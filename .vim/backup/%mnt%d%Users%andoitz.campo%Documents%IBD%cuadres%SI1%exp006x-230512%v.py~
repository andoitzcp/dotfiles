import pandas as pd
from alive_progress import alive_bar

# Path to files root directory
path = '/mnt/d/Users/andoitz.campo/Documents/IBD/cuadres/SI1/exp006x-230512/'

# Exported CSV list to be read
dict_xprt = {'p': 'p_zlgat.csv',
            'p_t087u': 'p_t087u.csv',
            'c': 'c.csv'}

# CSV list of filter to be applied
dict_fltr = {'drop_ceco': 'forbiden_cecos.csv',
            'drop_cebe': 'forbiden_cebes.csv'}

# Test definitions
dict_test = {'Actual': {},
             'Budget': {},
             'Comparative_Version': {},
             'Annual_Plan': {},
             'Quantity': {},
             'Power': {},
             'Capacity': {}}

# Agroupations
groups = ['COMPANY', 'COMPANY_GL', 'CECO','CEBE', 'BAREA', 'BAREA_GL']

# Data types specifications
datatypes = {'COMPANY': str,
             'COMPANY_GL': str,
          'VERSION': str,
          'ORDER': str,
          'BAREA': str,
          'BAREA_GL': str,
          'CECO': str,
          'CEBE': str,
          'YEAR': str,
          'UNIT': str,
          'AENE': float,
          'AFEB': float,
          'AMAR': float,
          'AABR': float,
          'AMAY': float,
          'AJUN': float,
          'AJUL': float,
          'AAGO': float,
          'ASEP': float,
          'AOCT': float,
          'ANOV': float,
          'ADIC': float,
          'QENE': float,
          'QFEB': float,
          'QMAR': float,
          'QABR': float,
          'QMAY': float,
          'QJUN': float,
          'QJUL': float,
          'QAGO': float,
          'QSEP': float,
          'QOCT': float,
          'QNOV': float,
          'QDIC': float,
          'CAPACITY': float,
          'POWER': float,
          'CTEST1' : float,
          'CTEST2' : float,
          'CTEST3' : float,
          'CTEST4' : float,
          'CTEST5' : float,
          'CTEST6' : float,
          'CTEST7' : float,
          'CTEST8' : float,
          'CTEST9' : float}

dict_dfs = {}
# Function that reads the handled CSV files.
def ft_readfiles(path, dict_xprt, dict_fltr, datatypes):
    n = len(dict_xprt) + len(dict_fltr)
    print("Reading CSV exported files")
    with alive_bar(n, bar='classic2', spinner='twirls') as bar:
        for key in dict_xprt:
            d = path + dict_xprt[key]
            df = pd.read_csv(d, sep=";", decimal=",", dtype=datatypes)
            dict_dfs[key] = df
            print(key, " readed. File name:", dict_xprt[key])
            bar()
        for key in dict_fltr:
            d = path + dict_fltr[key]
            df = pd.read_csv(d, sep=";", dtype=datatypes)
            dict_dfs[key] = df
            print(key, " readed. File name:", dict_fltr[key])
            bar()

def ft_joindfs(left_df, right_df, key, how):
    with alive_bar(1, bar=None, spinner='twirls') as bar:
        p = pd.merge(dict_dfs[left_df],
                     dict_dfs[right_df],
                     on=key,
                     how=how,
                     suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')
        tmp_dict = {'p': p}
        dict_dfs.update(tmp_dict)
        print(left_df, 'and', right_df, 'joined at', key, 'as', how)
        bar()

def ft_droplmnts(main_dfn, drop_dfn):
    with alive_bar(1, bar=None, spinner='twirls') as bar:
        tmp_mdf = dict_dfs[main_dfn].copy()
        tmp_ddf = dict_dfs[drop_dfn].copy()
        header = list(tmp_ddf.columns.values).pop(0)
        main_df = tmp_mdf[~tmp_mdf[header].isin(tmp_ddf[header])]
        del tmp_mdf, tmp_ddf
        dict_dfs.update({main_dfn: main_df})
        print('Listed', header, 'droped.')
        bar()

def ft_utest(test, tmp_dfp, src_dfc, fp, fc):
    cols_p = groups.copy()
    cols_p.append(fp)
    cols_c = groups.copy()
    cols_c.append(fc)
    dfp = tmp_dfp.copy()
    dfp = tmp_dfp.loc[:, cols_p]
    dfc = src_dfc.copy()
    dfc = src_dfc.loc[:, cols_c]
    dict_test[test].update({'p': dfp})
    dict_test[test].update({'c': dfc})
    dict_test[test].update({'fp': fp})
    dict_test[test].update({'fc': fc})
    del tmp_dfp

def ft_dfcmp():
    n = len(dict_test) * len(groups)
    with alive_bar(n, bar='classic2', spinner='twirls') as bar:
        for test in dict_test:
            print(f'\t {test}.\n')
            for group in groups:
                out_name = './out/' + test + group + '.csv'
                tmp_dict = dict_test[test]
                tmp_dfc = tmp_dict['c'].groupby(group).sum(numeric_only=True).reset_index()
                tmp_dfp = tmp_dict['p'].groupby(group).sum(numeric_only=True).reset_index()
                cmp = pd.merge(tmp_dfc,
                               tmp_dfp,
                               on=group,
                               how='left')
                cmp['DIFF'] = cmp[tmp_dict['fc']] - cmp[tmp_dict['fp']]
                tot_rows = cmp['DIFF'].count()
                ok_rows = cmp.loc[cmp['DIFF'].abs() < 1, 'DIFF'].count()
                if ok_rows == tot_rows:
                    isok = '\033[92m[OK]\033[0m'
                else:
                    isok = '\033[91m[NOK]\033[0m'
                cmp.to_csv(out_name)
                print(f'\t\t {group}: {ok_rows}/{tot_rows}\t{isok}\n')
                del cmp, tmp_dfc, tmp_dfp
                bar()

### Script instructions starts here ###
ft_readfiles(path, dict_xprt, dict_fltr, datatypes) # Reads CSVs
#dict_dfs['p']['ORDER'] = dict_dfs['p']['ORDER'].str.lstrip('0')
ft_joindfs('p', 'p_t087u', 'ORDER', 'left') # joins tables
ft_droplmnts('p', 'drop_ceco') # Drops CECOs
ft_droplmnts('p', 'drop_cebe') # Drops CEBEs

#Transformations
# TEST 1: Actual
tmp_df = dict_dfs['p'].copy()
tmp_df['P'] = (-1) * tmp_df.loc[tmp_df['VERSION'] == '1','AENE':'ASEP'].sum(axis=1)
ft_utest('Actual', tmp_df, dict_dfs['c'], 'P', 'CTEST1')

# TEST 2: Budget
tmp_df = dict_dfs['p'].copy()
tmp_df['P'] = (-1) * tmp_df.loc[tmp_df['VERSION'] == 'PAP','AENE':'ASEP'].sum(axis=1)
ft_utest('Budget', tmp_df, dict_dfs['c'], 'P', 'CTEST2')

# TEST 4: Comparative V
tmp_df = dict_dfs['p'].copy()
tmp_df['P'] = (-1) * tmp_df.loc[tmp_df['VERSION'] == 'ES1','AENE':'ASEP'].sum(axis=1)
ft_utest('Comparative_Version', tmp_df, dict_dfs['c'], 'P', 'CTEST4')

# TEST 6: Annual
tmp_df = dict_dfs['p'].copy()
tmp_df['P'] = (-1) * tmp_df.loc[tmp_df['VERSION'] == 'PAP','AENE':'ADIC'].sum(axis=1)
ft_utest('Annual_Plan', tmp_df, dict_dfs['c'], 'P', 'CTEST6')

# TEST 7: Quantity
tmp_df = dict_dfs['p'].copy()
tmp_df['P'] = (-1) * tmp_df.loc[tmp_df['VERSION'] == '1','QENE':'QDIC'].sum(axis=1)
ft_utest('Quantity', tmp_df, dict_dfs['c'], 'P', 'CTEST7')

# TEST 8: Power
tmp_df = dict_dfs['p'].copy()
ft_utest('Power', tmp_df, dict_dfs['c'], 'POWER', 'CTEST8')

# TEST 9: Capacity
tmp_df = dict_dfs['p'].copy()
ft_utest('Capacity', tmp_df, dict_dfs['c'], 'CAPACITY', 'CTEST9')

ft_dfcmp()
